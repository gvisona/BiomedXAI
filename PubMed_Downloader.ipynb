{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymed as pm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Query function\n",
    "def get_query_from_keywords(keywords):\n",
    "    query = ''\n",
    "    for keyword_set in keywords:\n",
    "        str_aux =''\n",
    "        for single_key in keyword_set:\n",
    "            if single_key==keyword_set[0]:\n",
    "                str_aux += f'({single_key}[Title/Abstract] OR '\n",
    "            elif single_key==keyword_set[-1]:\n",
    "                str_aux += f'{single_key}[Title/Abstract] OR '\n",
    "            else:\n",
    "                str_aux += f'{single_key}[Title/Abstract] OR '\n",
    "            \n",
    "            if single_key==keyword_set[0]:\n",
    "                str_aux += f'{single_key}[MeSH Major Topic] OR '\n",
    "            elif single_key==keyword_set[-1]:\n",
    "                str_aux += f'{single_key}[MeSH Major Topic])'\n",
    "            else:\n",
    "                str_aux += f'{single_key}[MeSH Major Topic] OR '\n",
    "        \n",
    "        if keyword_set==keywords[-1]:\n",
    "            query += str_aux \n",
    "        else:\n",
    "            query += str_aux + ' AND '\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query words\n",
    "Biomedical =  [\"Anesthesiology\", \"Biomedical\", \"Biomedicine\", \"Bioinformatics\", \"Cardiovascular\", \"Clinical\", \"Critical Care\", \"Dermatology\", \"Disease\", \"Drug\", \n",
    "                \"Gastroenterology\", \"Genetics\", \"Genomics\", \"Gynecology\", \"Health\", \"Healthcare\", \"Hematology\", \"Life sciences\", \"Medical\", \"Medicine\", \"Nephrology\", \n",
    "                \"Neurology\", \"Obstetrics\", \"Oncology\", \"Ophthalmology\", \"Orthopedic\", \"Pathology\", \"Pediatrics\", \"Pharmacology\",  \"Protein\", \"Psychiatry\", \"Radiology\", \n",
    "                \"Surgery\", \"Urology\", \"Vaccine\", \"Immunology\"]\n",
    "\n",
    "AI =  [\"AI\", \"Artificial Intelligence\", \"Deep Learning\", \"Machine Learning\"]\n",
    "\n",
    "XAI =  [\"Black Box Models\", \"Explainable\", \"Inerpretability\", \"Explainability\", \"Opacity\", \"Opaque\", \"xAI\"]\n",
    "\n",
    "Causal =  [\"Causal\", \"Causation\", \"Counterfactual\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biomed+Ai+xAI query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [Biomedical,AI, XAI]\n",
    "query_str = get_query_from_keywords(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBMED = pm.PubMed(tool=\"MyTool\", email='<USER EMAIL>')\n",
    "raw = PUBMED.query(query_period, max_results=9999)\n",
    "fulldump=list(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list containing paper information\n",
    "full_list_file= []\n",
    "for element in fulldump:\n",
    "    if element.abstract is not None and element.title is not None:\n",
    "        pass_criteria = [False, False, False] \n",
    "        for biomedicalkw in Biomedical:\n",
    "            if biomedicalkw.lower() in element.abstract.lower() or biomedicalkw in element.title.lower():\n",
    "                pass_criteria[0]=True\n",
    "                break\n",
    "        for aikw in AI:\n",
    "            if aikw.lower() in element.abstract.lower() or aikw in element.title.lower():\n",
    "                pass_criteria[1]=True\n",
    "                break\n",
    "        for xmlkw in XAI:\n",
    "            if xmlkw.lower() in element.abstract.lower() or xmlkw in element.title.lower():\n",
    "                pass_criteria[2]=True\n",
    "                break\n",
    "\n",
    "        if pass_criteria == [True, True, True]:\n",
    "            aut_list=''\n",
    "            for author in element.toDict()['authors']:\n",
    "                try:\n",
    "                    aut_list += author['lastname'] + ' ' + author['firstname'] +', '\n",
    "                except:\n",
    "                    aut_list+= 'None, '\n",
    "            aut_list=aut_list[:-2]\n",
    "            dict_aux={}\n",
    "            try:\n",
    "                dict_aux['title']=element.title\n",
    "            except:\n",
    "                dict_aux['title']='None'\n",
    "            try:\n",
    "                dict_aux['abstract']=element.abstract\n",
    "            except:\n",
    "                dict_aux['abstract']='None'\n",
    "            try:\n",
    "                dict_aux['doi']=element.doi\n",
    "            except:\n",
    "                dict_aux['doi']='None'\n",
    "            try:\n",
    "                dict_aux['journal']=element.journal\n",
    "            except:\n",
    "                dict_aux['journal']='None'\n",
    "            try:\n",
    "                dict_aux['date']=f'{element.publication_date.year}-{element.publication_date.month}-{element.publication_date.day}'\n",
    "            except:\n",
    "                dict_aux['date']='None'\n",
    "            try:\n",
    "                dict_aux['keywords']=element.keywords\n",
    "            except:\n",
    "                dict_aux['keywords']='None'\n",
    "            dict_aux['authors']=aut_list\n",
    "            full_list_file.append(dict_aux)\n",
    "\n",
    "dump_filename = 'papers_biomed_ai_xai.json'\n",
    "with open(dump_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_list_file, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract keywords from abstract and title\n",
    "\n",
    "with open('papers_biomed_ai_xai.json','r') as fullfile:\n",
    "    full_list_file=json.load(fullfile)\n",
    "\n",
    "keyword_list_biomed_ai_xai= []\n",
    "\n",
    "id = 0\n",
    "for paper in full_list_file:\n",
    "    keyword_list = []\n",
    "    if paper['abstract'] is not None and paper['title'] is not None:\n",
    "        for biomedicalkw in Biomedical:\n",
    "            if biomedicalkw in paper['abstract'] or biomedicalkw in paper['title'] or biomedicalkw in paper['keywords'] :\n",
    "                keyword_list.append(biomedicalkw)\n",
    "        for aikw in AI:\n",
    "            if aikw in paper['abstract'] or aikw in paper['title'] or aikw in paper['keywords']:\n",
    "                keyword_list.append(aikw)\n",
    "        for xmlkw in XAI:\n",
    "            if xmlkw in paper['abstract'] or xmlkw in paper['title'] or xmlkw in paper['keywords']:\n",
    "                keyword_list.append('Explainability')\n",
    "\n",
    "        keyword_dict = {}\n",
    "\n",
    "        keyword_dict['Index'] = id\n",
    "        keyword_dict['keywords'] = keyword_list\n",
    "\n",
    "        keyword_list_biomed_ai_xai.append(keyword_dict)\n",
    "\n",
    "    id += 1\n",
    "\n",
    "#write it on a json file\n",
    "dump_filename = 'keyword_biomed_ai_xai.json'\n",
    "\n",
    "with open(dump_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(keyword_list_biomed_ai_xai, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biomed+Ai+xAI+Causal query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [Biomedical,AI, XAI, Causal]\n",
    "query_str = get_query_from_keywords(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBMED = pm.PubMed(tool=\"MyTool\", email='<USER EMAIL>')\n",
    "raw = PUBMED.query(query_period, max_results=9999)\n",
    "fulldump=list(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list containing paper information\n",
    "full_list_file= []\n",
    "for element in fulldump:\n",
    "    if element.abstract is not None and element.title is not None:\n",
    "        pass_criteria = [False, False, False, False]\n",
    "        for biomedicalkw in Biomedical:\n",
    "            if biomedicalkw.lower() in element.abstract.lower() or biomedicalkw in element.title.lower():\n",
    "                pass_criteria[0]=True\n",
    "                break\n",
    "        for aikw in AI:\n",
    "            if aikw.lower() in element.abstract.lower() or aikw in element.title.lower():\n",
    "                pass_criteria[1]=True\n",
    "                break\n",
    "        for xmlkw in XAI:\n",
    "            if xmlkw.lower() in element.abstract.lower() or xmlkw in element.title.lower():\n",
    "                pass_criteria[2]=True\n",
    "                break\n",
    "        for causalkw in Causal:\n",
    "            if causalkw.lower() in element.abstract.lower() or causalkw in element.title.lower():\n",
    "                pass_criteria[3]=True\n",
    "                break\n",
    "        if pass_criteria == [True, True, True, True]:\n",
    "            aut_list=''\n",
    "            for author in element.toDict()['authors']:\n",
    "                try:\n",
    "                    aut_list += author['lastname'] + ' ' + author['firstname'] +', '\n",
    "                except:\n",
    "                    aut_list+= 'None, '\n",
    "            aut_list=aut_list[:-2]\n",
    "            dict_aux={}\n",
    "            try:\n",
    "                dict_aux['title']=element.title\n",
    "            except:\n",
    "                dict_aux['title']='None'\n",
    "            try:\n",
    "                dict_aux['abstract']=element.abstract\n",
    "            except:\n",
    "                dict_aux['abstract']='None'\n",
    "            try:\n",
    "                dict_aux['doi']=element.doi\n",
    "            except:\n",
    "                dict_aux['doi']='None'\n",
    "            try:\n",
    "                dict_aux['journal']=element.journal\n",
    "            except:\n",
    "                dict_aux['journal']='None'\n",
    "            try:\n",
    "                dict_aux['date']=f'{element.publication_date.year}-{element.publication_date.month}-{element.publication_date.day}'\n",
    "            except:\n",
    "                dict_aux['date']='None'\n",
    "            try:\n",
    "                dict_aux['keywords']=element.keywords\n",
    "            except:\n",
    "                dict_aux['keywords']='None'\n",
    "            dict_aux['authors']=aut_list\n",
    "            full_list_file.append(dict_aux)\n",
    "\n",
    "dump_filename = 'papers_biomed_ai_xai_causal.json'\n",
    "with open(dump_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_list_file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract keywords from abstract and title\n",
    "\n",
    "with open('JSON_files/papers_biomed_ai_xai_causal.json','r') as fullfile:\n",
    "    full_list_file=json.load(fullfile)\n",
    "\n",
    "keyword_list_biomed_ai_xai_causal= []\n",
    "\n",
    "id = 0\n",
    "for paper in full_list_file:\n",
    "    keyword_list = []\n",
    "    if paper['abstract'] is not None and paper['title'] is not None:\n",
    "        for biomedicalkw in Biomedical:\n",
    "            if biomedicalkw in paper['abstract'] or biomedicalkw in paper['title'] or biomedicalkw in paper['keywords'] :\n",
    "                keyword_list.append(biomedicalkw)\n",
    "        for aikw in AI:\n",
    "            if aikw in paper['abstract'] or aikw in paper['title'] or aikw in paper['keywords']:\n",
    "                keyword_list.append(aikw)\n",
    "        for xmlkw in XAI:\n",
    "            if xmlkw in paper['abstract'] or xmlkw in paper['title'] or xmlkw in paper['keywords']:\n",
    "                keyword_list.append('Explainability')\n",
    "        for causalkw in Causal:\n",
    "            if causalkw in paper['abstract'] or causalkw in paper['title'] or causalkw in paper['keywords']:\n",
    "                keyword_list.append('Causal')\n",
    "\n",
    "        keyword_dict = {}\n",
    "\n",
    "        keyword_dict['Index'] = id\n",
    "        keyword_dict['keywords'] = keyword_list\n",
    "\n",
    "        keyword_list_biomed_ai_xai_causal.append(keyword_dict)\n",
    "\n",
    "    id += 1\n",
    "\n",
    "#write it on a json file\n",
    "dump_filename = 'keyword_biomed_ai_xai_causal.json'\n",
    "\n",
    "with open(dump_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(keyword_list_biomed_ai_xai_causal, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "116c8fcb328b67faa4f82de808f934c89ebe6dff4d3edd25eb273fd0b540170d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
